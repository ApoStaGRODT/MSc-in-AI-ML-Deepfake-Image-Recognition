{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe66a015-09eb-41cc-95ee-1f9b6bd8112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929a9986-adf4-4005-a7d0-2c8d4a1092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['lbp'] #We can change this to add 'hog', 'color', or 'gabor'.\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=1),\n",
    "    'SVM': SVC(random_state=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f322bd7-8fd4-42c5-b11b-62b84f882c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions help set a loop/pipeline for experimenting with different features/models.\n",
    "def load_and_combine_features(real_path, fake_path, features_to_use):\n",
    "    #We load real and fake features, combine them with labels.\n",
    "    real_data = np.load(real_path)\n",
    "    fake_data = np.load(fake_path)\n",
    "\n",
    "    #We extract and concatenate selected features.\n",
    "    real_features = np.concatenate([real_data[feature] for feature in features_to_use], axis=1)\n",
    "    fake_features = np.concatenate([fake_data[feature] for feature in features_to_use], axis=1)\n",
    "\n",
    "    #We combine real and fake images.\n",
    "    X = np.vstack([real_features, fake_features])\n",
    "    y = np.hstack([np.zeros(len(real_features)), np.ones(len(fake_features))])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def print_metrics(y_true, y_pred, dataset_name, model_namme):\n",
    "    #We choose the following evaluation metrics.\n",
    "    Acc = accuracy_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{model_name} - {dataset_name} Results:\")\n",
    "    print(f\" Accuracy: {Acc:.4f}\")\n",
    "    print(f\" F1 Score: {F1:.4f}\")\n",
    "    print(f\" Confusion Matrix:\")\n",
    "    print(f\"   {cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c54c57-b6b3-4d53-871e-1c1caf352003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Features...\n",
      "Train set: (10000, 10), Valid set: (2000, 10), Test set: (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Time to load the data.\n",
    "print(\"Loading Features...\")\n",
    "X_train, y_train = load_and_combine_features(\n",
    "    'train_real_all_features.npz',\n",
    "    'train_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "\n",
    "X_valid, y_valid = load_and_combine_features(\n",
    "    'valid_real_all_features.npz',\n",
    "    'valid_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "\n",
    "X_test, y_test = load_and_combine_features(\n",
    "    'test_real_all_features.npz',\n",
    "    'test_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Valid set: {X_valid.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f34d4b5-5725-4eb5-811d-e0b18acc9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features...\n",
      "Scaler saved to 'scaler.joblib'\n"
     ]
    }
   ],
   "source": [
    "#For LBP it is recommended to scale the features.\n",
    "print(\"\\nScaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Save scaler\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "print(\"Scaler saved to 'scaler.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f181380-1ba9-4cc3-bb02-a2db131eda76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Training Random Forest ...\n",
      "\n",
      "Random Forest - Train Results:\n",
      " Accuracy: 1.0000\n",
      " F1 Score: 1.0000\n",
      " Confusion Matrix:\n",
      "   [[5000    0]\n",
      " [   0 5000]]\n",
      "\n",
      "Random Forest - Valid Results:\n",
      " Accuracy: 0.6240\n",
      " F1 Score: 0.6259\n",
      " Confusion Matrix:\n",
      "   [[619 381]\n",
      " [371 629]]\n",
      "\n",
      "Random Forest - Test Results:\n",
      " Accuracy: 0.6310\n",
      " F1 Score: 0.6411\n",
      " Confusion Matrix:\n",
      "   [[603 397]\n",
      " [341 659]]\n",
      "\n",
      "Model saved to 'random_forest_model.joblib'\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Training Gradient Boosting ...\n",
      "\n",
      "Gradient Boosting - Train Results:\n",
      " Accuracy: 0.6769\n",
      " F1 Score: 0.6965\n",
      " Confusion Matrix:\n",
      "   [[3062 1938]\n",
      " [1293 3707]]\n",
      "\n",
      "Gradient Boosting - Valid Results:\n",
      " Accuracy: 0.6180\n",
      " F1 Score: 0.6430\n",
      " Confusion Matrix:\n",
      "   [[548 452]\n",
      " [312 688]]\n",
      "\n",
      "Gradient Boosting - Test Results:\n",
      " Accuracy: 0.6210\n",
      " F1 Score: 0.6428\n",
      " Confusion Matrix:\n",
      "   [[560 440]\n",
      " [318 682]]\n",
      "\n",
      "Model saved to 'gradient_boosting_model.joblib'\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Training SVM ...\n",
      "\n",
      "SVM - Train Results:\n",
      " Accuracy: 0.6625\n",
      " F1 Score: 0.6953\n",
      " Confusion Matrix:\n",
      "   [[2774 2226]\n",
      " [1149 3851]]\n",
      "\n",
      "SVM - Valid Results:\n",
      " Accuracy: 0.6350\n",
      " F1 Score: 0.6706\n",
      " Confusion Matrix:\n",
      "   [[527 473]\n",
      " [257 743]]\n",
      "\n",
      "SVM - Test Results:\n",
      " Accuracy: 0.6410\n",
      " F1 Score: 0.6763\n",
      " Confusion Matrix:\n",
      "   [[532 468]\n",
      " [250 750]]\n",
      "\n",
      "Model saved to 'svm_model.joblib'\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "All models trained and saved.\n"
     ]
    }
   ],
   "source": [
    "#Time to train and evaluate all models.\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'+'*50}\")\n",
    "    print(f\"Training {model_name} ...\")\n",
    "\n",
    "    #Training.\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    #Predicting on all sets.\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_valid_pred = model.predict(X_valid_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    #Printing metrics.\n",
    "    print_metrics(y_train, y_train_pred, \"Train\", model_name)\n",
    "    print_metrics(y_valid, y_valid_pred, \"Valid\", model_name)\n",
    "    print_metrics(y_test, y_test_pred, \"Test\", model_name)\n",
    "\n",
    "    #Saving models.\n",
    "    model_filename = f\"{model_name.lower().replace(' ', '_')}_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"\\nModel saved to '{model_filename}'\")\n",
    "\n",
    "    #Storing in dictionary.\n",
    "    trained_models[model_name] = model\n",
    "\n",
    "print(\"\\n\" + \"+\"*50)\n",
    "print(\"All models trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7812797-f2c0-40c0-9b6c-98a156bf01e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
