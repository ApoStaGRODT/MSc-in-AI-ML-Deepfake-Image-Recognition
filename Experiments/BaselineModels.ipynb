{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe66a015-09eb-41cc-95ee-1f9b6bd8112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"TBB\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929a9986-adf4-4005-a7d0-2c8d4a1092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['lbp', 'hog', 'color', 'gabor'] #Added all features for baseline.\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=1),\n",
    "    'SVM': SVC(random_state=1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f322bd7-8fd4-42c5-b11b-62b84f882c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions help set a loop/pipeline for experimenting with different features/models.\n",
    "def load_and_combine_features(real_path, fake_path, features_to_use):\n",
    "    #We load real and fake features, combine them with labels.\n",
    "    real_data = np.load(real_path)\n",
    "    fake_data = np.load(fake_path)\n",
    "\n",
    "    #Print individual feature dimensions.\n",
    "    print(f\"  Feature dimensions in {real_path}:\")\n",
    "    for feature in features_to_use:\n",
    "        print(f\"    {feature}: {real_data[feature].shape[1]} features\")\n",
    "    \n",
    "    #We extract and concatenate selected features.\n",
    "    real_features = np.concatenate([real_data[feature] for feature in features_to_use], axis=1)\n",
    "    fake_features = np.concatenate([fake_data[feature] for feature in features_to_use], axis=1)\n",
    "\n",
    "    #We combine real and fake images.\n",
    "    X = np.vstack([real_features, fake_features])\n",
    "    y = np.hstack([np.zeros(len(real_features)), np.ones(len(fake_features))])\n",
    "    return X, y\n",
    "\n",
    "def print_metrics(y_true, y_pred, y_pred_proba, dataset_name, model_name):\n",
    "    #We choose the following evaluation metrics.\n",
    "    Acc = accuracy_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred)\n",
    "    Precision = precision_score(y_true, y_pred)\n",
    "    Recall = recall_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    #Calculate ROC-AUC.\n",
    "    if y_pred_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    #Extract confusion matrix values.\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    print(f\"\\n{model_name} - {dataset_name} Results:\")\n",
    "    print(f\" Accuracy: {Acc:.4f}\")\n",
    "    print(f\" Precision: {Precision:.4f}\")\n",
    "    print(f\" Recall: {Recall:.4f}\")\n",
    "    print(f\" F1 Score: {F1:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\" ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\" Confusion Matrix:\")\n",
    "    print(f\"   {cm}\")\n",
    "\n",
    "    print(f\"\\n CONFUSION MATRIX BREAKDOWN:\")\n",
    "    print(f\"  True Negatives  (TN): {tn:4d} - Correctly identified as Fake\")\n",
    "    print(f\"  False Positives (FP): {fp:4d} - Fake wrongly identified as Real\")\n",
    "    print(f\"  False Negatives (FN): {fn:4d} - Real wrongly identified as Fake\")\n",
    "    print(f\"  True Positives  (TP): {tp:4d} - Correctly identified as Real\")\n",
    "    \n",
    "    #Detailed Error analysis.\n",
    "    total_errors = fp + fn\n",
    "    total_samples = len(y_true)\n",
    "    print(f\"\\n ERROR ANALYSIS:\")\n",
    "    print(f\"  Total Errors: {total_errors}/{total_samples} ({total_errors/total_samples*100:.2f}%)\")\n",
    "    print(f\"  False Positives: {fp} ({fp/total_samples*100:.2f}%) - Fake images classified as Real\")\n",
    "    print(f\"  False Negatives: {fn} ({fn/total_samples*100:.2f}%) - Real images classified as Fake\")\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c54c57-b6b3-4d53-871e-1c1caf352003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train ---\n",
      "  Feature dimensions in train_real_all_features.npz:\n",
      "    lbp: 59 features\n",
      "    hog: 1764 features\n",
      "    color: 6 features\n",
      "    gabor: 8 features\n",
      "\n",
      "--- Validation ---\n",
      "  Feature dimensions in valid_real_all_features.npz:\n",
      "    lbp: 59 features\n",
      "    hog: 1764 features\n",
      "    color: 6 features\n",
      "    gabor: 8 features\n",
      "\n",
      "--- Test ---\n",
      "  Feature dimensions in test_real_all_features.npz:\n",
      "    lbp: 59 features\n",
      "    hog: 1764 features\n",
      "    color: 6 features\n",
      "    gabor: 8 features\n",
      "\n",
      "Train set: (10000, 1837), Valid set: (2000, 1837), Test set: (2000, 1837)\n",
      "Total features used: 1837\n",
      "\n",
      "--- Class Balance ---\n",
      "Train - Real: 5000, Fake: 5000\n",
      "Valid - Real: 1000, Fake: 1000\n",
      "Test  - Real: 1000, Fake: 1000\n"
     ]
    }
   ],
   "source": [
    "#Time to load the data.\n",
    "print(\"\\n--- Train ---\")\n",
    "X_train, y_train = load_and_combine_features(\n",
    "    'train_real_all_features.npz',\n",
    "    'train_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "print(\"\\n--- Validation ---\")\n",
    "X_valid, y_valid = load_and_combine_features(\n",
    "    'valid_real_all_features.npz',\n",
    "    'valid_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "print(\"\\n--- Test ---\")\n",
    "X_test, y_test = load_and_combine_features(\n",
    "    'test_real_all_features.npz',\n",
    "    'test_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}, Valid set: {X_valid.shape}, Test set: {X_test.shape}\")\n",
    "print(f\"Total features used: {X_train.shape[1]}\")\n",
    "\n",
    "print(\"\\n--- Class Balance ---\")\n",
    "print(f\"Train - Real: {np.sum(y_train == 0)}, Fake: {np.sum(y_train == 1)}\")\n",
    "print(f\"Valid - Real: {np.sum(y_valid == 0)}, Fake: {np.sum(y_valid == 1)}\")\n",
    "print(f\"Test  - Real: {np.sum(y_test == 0)}, Fake: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f34d4b5-5725-4eb5-811d-e0b18acc9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features\n",
      "Scaler saved to 'scaler.joblib'\n"
     ]
    }
   ],
   "source": [
    "#Scaling all features.\n",
    "print(\"\\nScaling features\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Save scaler.\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "print(\"Scaler saved to 'scaler.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f181380-1ba9-4cc3-bb02-a2db131eda76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++\n",
      "Training Random Forest\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "#Time to train and evaluate all models.\n",
    "trained_models = {}\n",
    "roc_data = {} #Store ROC curve data for plotting.\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'+'*25}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    #Start timing.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Training.\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #End timing.\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "\n",
    "    #Predicting on all sets.\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_valid_pred = model.predict(X_valid_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Check if model supports predict_proba to get probability predictions for ROC-AUC.\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_proba = model.predict_proba(X_train_scaled)[:, 1]\n",
    "        y_valid_proba = model.predict_proba(X_valid_scaled)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):  #For SVM.\n",
    "        y_train_proba = model.decision_function(X_train_scaled)\n",
    "        y_valid_proba = model.decision_function(X_valid_scaled)\n",
    "        y_test_proba = model.decision_function(X_test_scaled)\n",
    "    else:\n",
    "        y_train_proba = None\n",
    "        y_valid_proba = None\n",
    "        y_test_proba = None\n",
    "\n",
    "    #Printing metrics.\n",
    "    print_metrics(y_train, y_train_pred, y_train_proba, \"Train\", model_name)\n",
    "    valid_auc = print_metrics(y_valid, y_valid_pred, y_valid_proba, \"Valid\", model_name)\n",
    "    test_auc = print_metrics(y_test, y_test_pred, y_test_proba, \"Test\", model_name)\n",
    "    \n",
    "    #Store ROC curve data for validation set.\n",
    "    if y_valid_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_valid, y_valid_proba)\n",
    "        roc_data[model_name] = {\n",
    "            'fpr': fpr, \n",
    "            'tpr': tpr, \n",
    "            'auc': valid_auc,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "\n",
    "    #Saving models.\n",
    "    model_filename = f\"{model_name.lower().replace(' ', '_')}_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"\\nModel saved to '{model_filename}'\")\n",
    "\n",
    "    #Storing in dictionary.\n",
    "    trained_models[model_name] = model\n",
    "\n",
    "print(\"\\n\" + \"=\"*25)\n",
    "print(\"Baseline: All models trained and saved with all features (lbp, hog, color, gabor)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7812797-f2c0-40c0-9b6c-98a156bf01e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
