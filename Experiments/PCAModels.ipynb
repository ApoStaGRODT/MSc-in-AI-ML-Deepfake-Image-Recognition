{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe66a015-09eb-41cc-95ee-1f9b6bd8112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"TBB\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "929a9986-adf4-4005-a7d0-2c8d4a1092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['lbp', 'hog', 'color', 'gabor'] #Added all features for baseline.\n",
    "use_pca = True #This way we can enable/disable PCA.\n",
    "pca_variance_threshold = 0.95 #Keep components explaining 95% of variance.\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=1),\n",
    "    'SVM': SVC(random_state=1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f322bd7-8fd4-42c5-b11b-62b84f882c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions help set a loop/pipeline for experimenting with different features/models.\n",
    "def load_and_combine_features(real_path, fake_path, features_to_use):\n",
    "    #We load real and fake features, combine them with labels.\n",
    "    real_data = np.load(real_path)\n",
    "    fake_data = np.load(fake_path)\n",
    "\n",
    "    #Print individual feature dimensions.\n",
    "    print(f\"  Feature dimensions in {real_path}:\")\n",
    "    for feature in features_to_use:\n",
    "        print(f\"    {feature}: {real_data[feature].shape[1]} features\")\n",
    "    \n",
    "    #We extract and concatenate selected features.\n",
    "    real_features = np.concatenate([real_data[feature] for feature in features_to_use], axis=1)\n",
    "    fake_features = np.concatenate([fake_data[feature] for feature in features_to_use], axis=1)\n",
    "\n",
    "    #We combine real and fake images.\n",
    "    X = np.vstack([real_features, fake_features])\n",
    "    y = np.hstack([np.zeros(len(real_features)), np.ones(len(fake_features))])\n",
    "    return X, y\n",
    "\n",
    "def print_metrics(y_true, y_pred, y_pred_proba, dataset_name, model_name):\n",
    "    #We choose the following evaluation metrics.\n",
    "    Acc = accuracy_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred)\n",
    "    Precision = precision_score(y_true, y_pred)\n",
    "    Recall = recall_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    #Calculate ROC-AUC.\n",
    "    if y_pred_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    #Extract confusion matrix values.\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    print(f\"\\n{model_name} - {dataset_name} Results:\")\n",
    "    print(f\" Accuracy: {Acc:.4f}\")\n",
    "    print(f\" Precision: {Precision:.4f}\")\n",
    "    print(f\" Recall: {Recall:.4f}\")\n",
    "    print(f\" F1 Score: {F1:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\" ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\" Confusion Matrix:\")\n",
    "    print(f\"   {cm}\")\n",
    "\n",
    "    print(f\"\\n CONFUSION MATRIX BREAKDOWN:\")\n",
    "    print(f\"  True Negatives  (TN): {tn:4d} - Correctly identified as Fake\")\n",
    "    print(f\"  False Positives (FP): {fp:4d} - Fake wrongly identified as Real\")\n",
    "    print(f\"  False Negatives (FN): {fn:4d} - Real wrongly identified as Fake\")\n",
    "    print(f\"  True Positives  (TP): {tp:4d} - Correctly identified as Real\")\n",
    "    \n",
    "    #Detailed Error analysis.\n",
    "    total_errors = fp + fn\n",
    "    total_samples = len(y_true)\n",
    "    print(f\"\\n ERROR ANALYSIS:\")\n",
    "    print(f\"  Total Errors: {total_errors}/{total_samples} ({total_errors/total_samples*100:.2f}%)\")\n",
    "    print(f\"  False Positives: {fp} ({fp/total_samples*100:.2f}%) - Fake images classified as Real\")\n",
    "    print(f\"  False Negatives: {fn} ({fn/total_samples*100:.2f}%) - Real images classified as Fake\")\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90c54c57-b6b3-4d53-871e-1c1caf352003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train ---\n",
      "  Feature dimensions in train_real_all_features.npz:\n",
      "    lbp: 59 features\n",
      "    hog: 1764 features\n",
      "    color: 6 features\n",
      "    gabor: 8 features\n",
      "\n",
      "--- Validation ---\n",
      "  Feature dimensions in valid_real_all_features.npz:\n",
      "    lbp: 59 features\n",
      "    hog: 1764 features\n",
      "    color: 6 features\n",
      "    gabor: 8 features\n",
      "\n",
      "--- Test ---\n",
      "  Feature dimensions in test_real_all_features.npz:\n",
      "    lbp: 59 features\n",
      "    hog: 1764 features\n",
      "    color: 6 features\n",
      "    gabor: 8 features\n",
      "\n",
      "Train set: (10000, 1837), Valid set: (2000, 1837), Test set: (2000, 1837)\n",
      "Total features used: 1837\n",
      "\n",
      "--- Class Balance ---\n",
      "Train - Real: 5000, Fake: 5000\n",
      "Valid - Real: 1000, Fake: 1000\n",
      "Test  - Real: 1000, Fake: 1000\n"
     ]
    }
   ],
   "source": [
    "#Time to load the data.\n",
    "print(\"\\n--- Train ---\")\n",
    "X_train, y_train = load_and_combine_features(\n",
    "    'train_real_all_features.npz',\n",
    "    'train_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "print(\"\\n--- Validation ---\")\n",
    "X_valid, y_valid = load_and_combine_features(\n",
    "    'valid_real_all_features.npz',\n",
    "    'valid_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "print(\"\\n--- Test ---\")\n",
    "X_test, y_test = load_and_combine_features(\n",
    "    'test_real_all_features.npz',\n",
    "    'test_fake_all_features.npz',\n",
    "    features_to_use\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}, Valid set: {X_valid.shape}, Test set: {X_test.shape}\")\n",
    "print(f\"Total features used: {X_train.shape[1]}\")\n",
    "\n",
    "print(\"\\n--- Class Balance ---\")\n",
    "print(f\"Train - Real: {np.sum(y_train == 0)}, Fake: {np.sum(y_train == 1)}\")\n",
    "print(f\"Valid - Real: {np.sum(y_valid == 0)}, Fake: {np.sum(y_valid == 1)}\")\n",
    "print(f\"Test  - Real: {np.sum(y_test == 0)}, Fake: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f34d4b5-5725-4eb5-811d-e0b18acc9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features\n",
      "Scaler saved to 'scaler.joblib'\n"
     ]
    }
   ],
   "source": [
    "#Scaling all features (before PCA).\n",
    "print(\"\\nScaling features\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Save scaler.\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "print(\"Scaler saved to 'scaler.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bad2ddfb-65c4-4520-b731-b80ec03f1d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA Results:\n",
      " Original features: 1837\n",
      " Components retained: 480\n",
      " Explained variance: 0.9501 (95.01%)\n",
      " Dimensionality reduction: 1837 --> 480\n",
      "PCA saved to 'pca.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#Apply PCA.\n",
    "if use_pca:\n",
    "    #We fit PCA on training data only.\n",
    "    pca = PCA(n_components=pca_variance_threshold, random_state=1)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "    #We transform validation and test using the fitted PCA.\n",
    "    X_valid_pca = pca.transform(X_valid_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    n_components = pca.n_components_\n",
    "    explained_var = np.sum(pca.explained_variance_ratio_)\n",
    "    print(f\"\\nPCA Results:\")\n",
    "    print(f\" Original features: {X_train_scaled.shape[1]}\")\n",
    "    print(f\" Components retained: {n_components}\")\n",
    "    print(f\" Explained variance: {explained_var:.4f} ({explained_var*100:.2f}%)\")\n",
    "    print(f\" Dimensionality reduction: {X_train_scaled.shape[1]} --> {n_components}\")\n",
    "\n",
    "    joblib.dump(pca, 'pca.joblib')\n",
    "    print(\"PCA saved to 'pca.joblib\")\n",
    "\n",
    "    #Use PCA-transformed data for training.\n",
    "    X_train_scaled = X_train_pca\n",
    "    X_valid_scaled = X_valid_pca\n",
    "    X_test_scaled = X_test_pca\n",
    "\n",
    "else:\n",
    "    print(\"\\nPCA Disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f181380-1ba9-4cc3-bb02-a2db131eda76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++\n",
      "Training Random Forest\n",
      "\n",
      "Training completed in 15.07 seconds\n",
      "\n",
      "Random Forest - Train Results:\n",
      " Accuracy: 1.0000\n",
      " Precision: 1.0000\n",
      " Recall: 1.0000\n",
      " F1 Score: 1.0000\n",
      " ROC-AUC: 1.0000\n",
      " Confusion Matrix:\n",
      "   [[5000    0]\n",
      " [   0 5000]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN): 5000 - Correctly identified as Fake\n",
      "  False Positives (FP):    0 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):    0 - Real wrongly identified as Fake\n",
      "  True Positives  (TP): 5000 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 0/10000 (0.00%)\n",
      "  False Positives: 0 (0.00%) - Fake images classified as Real\n",
      "  False Negatives: 0 (0.00%) - Real images classified as Fake\n",
      "\n",
      "Random Forest - Valid Results:\n",
      " Accuracy: 0.7195\n",
      " Precision: 0.7318\n",
      " Recall: 0.6930\n",
      " F1 Score: 0.7119\n",
      " ROC-AUC: 0.7912\n",
      " Confusion Matrix:\n",
      "   [[746 254]\n",
      " [307 693]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  746 - Correctly identified as Fake\n",
      "  False Positives (FP):  254 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  307 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  693 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 561/2000 (28.05%)\n",
      "  False Positives: 254 (12.70%) - Fake images classified as Real\n",
      "  False Negatives: 307 (15.35%) - Real images classified as Fake\n",
      "\n",
      "Random Forest - Test Results:\n",
      " Accuracy: 0.7280\n",
      " Precision: 0.7468\n",
      " Recall: 0.6900\n",
      " F1 Score: 0.7173\n",
      " ROC-AUC: 0.8065\n",
      " Confusion Matrix:\n",
      "   [[766 234]\n",
      " [310 690]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  766 - Correctly identified as Fake\n",
      "  False Positives (FP):  234 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  310 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  690 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 544/2000 (27.20%)\n",
      "  False Positives: 234 (11.70%) - Fake images classified as Real\n",
      "  False Negatives: 310 (15.50%) - Real images classified as Fake\n",
      "\n",
      "Model saved to 'random_forest_model.joblib'\n",
      "\n",
      "+++++++++++++++++++++++++\n",
      "Training Gradient Boosting\n",
      "\n",
      "Training completed in 93.39 seconds\n",
      "\n",
      "Gradient Boosting - Train Results:\n",
      " Accuracy: 0.8331\n",
      " Precision: 0.8241\n",
      " Recall: 0.8470\n",
      " F1 Score: 0.8354\n",
      " ROC-AUC: 0.9133\n",
      " Confusion Matrix:\n",
      "   [[4096  904]\n",
      " [ 765 4235]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN): 4096 - Correctly identified as Fake\n",
      "  False Positives (FP):  904 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  765 - Real wrongly identified as Fake\n",
      "  True Positives  (TP): 4235 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 1669/10000 (16.69%)\n",
      "  False Positives: 904 (9.04%) - Fake images classified as Real\n",
      "  False Negatives: 765 (7.65%) - Real images classified as Fake\n",
      "\n",
      "Gradient Boosting - Valid Results:\n",
      " Accuracy: 0.7325\n",
      " Precision: 0.7151\n",
      " Recall: 0.7730\n",
      " F1 Score: 0.7429\n",
      " ROC-AUC: 0.8063\n",
      " Confusion Matrix:\n",
      "   [[692 308]\n",
      " [227 773]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  692 - Correctly identified as Fake\n",
      "  False Positives (FP):  308 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  227 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  773 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 535/2000 (26.75%)\n",
      "  False Positives: 308 (15.40%) - Fake images classified as Real\n",
      "  False Negatives: 227 (11.35%) - Real images classified as Fake\n",
      "\n",
      "Gradient Boosting - Test Results:\n",
      " Accuracy: 0.7475\n",
      " Precision: 0.7311\n",
      " Recall: 0.7830\n",
      " F1 Score: 0.7562\n",
      " ROC-AUC: 0.8270\n",
      " Confusion Matrix:\n",
      "   [[712 288]\n",
      " [217 783]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  712 - Correctly identified as Fake\n",
      "  False Positives (FP):  288 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  217 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  783 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 505/2000 (25.25%)\n",
      "  False Positives: 288 (14.40%) - Fake images classified as Real\n",
      "  False Negatives: 217 (10.85%) - Real images classified as Fake\n",
      "\n",
      "Model saved to 'gradient_boosting_model.joblib'\n",
      "\n",
      "+++++++++++++++++++++++++\n",
      "Training SVM\n",
      "\n",
      "Training completed in 7.43 seconds\n",
      "\n",
      "SVM - Train Results:\n",
      " Accuracy: 0.9563\n",
      " Precision: 0.9557\n",
      " Recall: 0.9570\n",
      " F1 Score: 0.9563\n",
      " ROC-AUC: 0.9914\n",
      " Confusion Matrix:\n",
      "   [[4778  222]\n",
      " [ 215 4785]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN): 4778 - Correctly identified as Fake\n",
      "  False Positives (FP):  222 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  215 - Real wrongly identified as Fake\n",
      "  True Positives  (TP): 4785 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 437/10000 (4.37%)\n",
      "  False Positives: 222 (2.22%) - Fake images classified as Real\n",
      "  False Negatives: 215 (2.15%) - Real images classified as Fake\n",
      "\n",
      "SVM - Valid Results:\n",
      " Accuracy: 0.8265\n",
      " Precision: 0.8167\n",
      " Recall: 0.8420\n",
      " F1 Score: 0.8291\n",
      " ROC-AUC: 0.9010\n",
      " Confusion Matrix:\n",
      "   [[811 189]\n",
      " [158 842]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  811 - Correctly identified as Fake\n",
      "  False Positives (FP):  189 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  158 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  842 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 347/2000 (17.35%)\n",
      "  False Positives: 189 (9.45%) - Fake images classified as Real\n",
      "  False Negatives: 158 (7.90%) - Real images classified as Fake\n",
      "\n",
      "SVM - Test Results:\n",
      " Accuracy: 0.8240\n",
      " Precision: 0.8183\n",
      " Recall: 0.8330\n",
      " F1 Score: 0.8256\n",
      " ROC-AUC: 0.9089\n",
      " Confusion Matrix:\n",
      "   [[815 185]\n",
      " [167 833]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  815 - Correctly identified as Fake\n",
      "  False Positives (FP):  185 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):  167 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  833 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 352/2000 (17.60%)\n",
      "  False Positives: 185 (9.25%) - Fake images classified as Real\n",
      "  False Negatives: 167 (8.35%) - Real images classified as Fake\n",
      "\n",
      "Model saved to 'svm_model.joblib'\n",
      "\n",
      "+++++++++++++++++++++++++\n",
      "Training KNN\n",
      "\n",
      "Training completed in 0.01 seconds\n",
      "\n",
      "KNN - Train Results:\n",
      " Accuracy: 1.0000\n",
      " Precision: 1.0000\n",
      " Recall: 1.0000\n",
      " F1 Score: 1.0000\n",
      " ROC-AUC: 1.0000\n",
      " Confusion Matrix:\n",
      "   [[5000    0]\n",
      " [   0 5000]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN): 5000 - Correctly identified as Fake\n",
      "  False Positives (FP):    0 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):    0 - Real wrongly identified as Fake\n",
      "  True Positives  (TP): 5000 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 0/10000 (0.00%)\n",
      "  False Positives: 0 (0.00%) - Fake images classified as Real\n",
      "  False Negatives: 0 (0.00%) - Real images classified as Fake\n",
      "\n",
      "KNN - Valid Results:\n",
      " Accuracy: 0.6090\n",
      " Precision: 0.5656\n",
      " Recall: 0.9400\n",
      " F1 Score: 0.7062\n",
      " ROC-AUC: 0.6090\n",
      " Confusion Matrix:\n",
      "   [[278 722]\n",
      " [ 60 940]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  278 - Correctly identified as Fake\n",
      "  False Positives (FP):  722 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):   60 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  940 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 782/2000 (39.10%)\n",
      "  False Positives: 722 (36.10%) - Fake images classified as Real\n",
      "  False Negatives: 60 (3.00%) - Real images classified as Fake\n",
      "\n",
      "KNN - Test Results:\n",
      " Accuracy: 0.5945\n",
      " Precision: 0.5570\n",
      " Recall: 0.9240\n",
      " F1 Score: 0.6950\n",
      " ROC-AUC: 0.5945\n",
      " Confusion Matrix:\n",
      "   [[265 735]\n",
      " [ 76 924]]\n",
      "\n",
      " CONFUSION MATRIX BREAKDOWN:\n",
      "  True Negatives  (TN):  265 - Correctly identified as Fake\n",
      "  False Positives (FP):  735 - Fake wrongly identified as Real\n",
      "  False Negatives (FN):   76 - Real wrongly identified as Fake\n",
      "  True Positives  (TP):  924 - Correctly identified as Real\n",
      "\n",
      " ERROR ANALYSIS:\n",
      "  Total Errors: 811/2000 (40.55%)\n",
      "  False Positives: 735 (36.75%) - Fake images classified as Real\n",
      "  False Negatives: 76 (3.80%) - Real images classified as Fake\n",
      "\n",
      "Model saved to 'knn_model.joblib'\n",
      "\n",
      "=========================\n",
      "Baseline: All models trained and saved with all features (lbp, hog, color, gabor)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "#Time to train and evaluate all models.\n",
    "trained_models = {}\n",
    "roc_data = {} #Store ROC curve data for plotting.\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'+'*25}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    #Start timing.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Training.\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #End timing.\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "\n",
    "    #Predicting on all sets.\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_valid_pred = model.predict(X_valid_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Check if model supports predict_proba to get probability predictions for ROC-AUC.\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_proba = model.predict_proba(X_train_scaled)[:, 1]\n",
    "        y_valid_proba = model.predict_proba(X_valid_scaled)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):  #For SVM.\n",
    "        y_train_proba = model.decision_function(X_train_scaled)\n",
    "        y_valid_proba = model.decision_function(X_valid_scaled)\n",
    "        y_test_proba = model.decision_function(X_test_scaled)\n",
    "    else:\n",
    "        y_train_proba = None\n",
    "        y_valid_proba = None\n",
    "        y_test_proba = None\n",
    "\n",
    "    #Printing metrics.\n",
    "    print_metrics(y_train, y_train_pred, y_train_proba, \"Train\", model_name)\n",
    "    valid_auc = print_metrics(y_valid, y_valid_pred, y_valid_proba, \"Valid\", model_name)\n",
    "    test_auc = print_metrics(y_test, y_test_pred, y_test_proba, \"Test\", model_name)\n",
    "    \n",
    "    #Store ROC curve data for validation set.\n",
    "    if y_valid_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_valid, y_valid_proba)\n",
    "        roc_data[model_name] = {\n",
    "            'fpr': fpr, \n",
    "            'tpr': tpr, \n",
    "            'auc': valid_auc,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "\n",
    "    #Saving models.\n",
    "    model_filename = f\"{model_name.lower().replace(' ', '_')}_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"\\nModel saved to '{model_filename}'\")\n",
    "\n",
    "    #Storing in dictionary.\n",
    "    trained_models[model_name] = model\n",
    "\n",
    "print(\"\\n\" + \"=\"*25)\n",
    "print(\"Baseline: All models trained and saved with all features (lbp, hog, color, gabor)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7812797-f2c0-40c0-9b6c-98a156bf01e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
